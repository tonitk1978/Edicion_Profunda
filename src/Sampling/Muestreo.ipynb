{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inicio del proceso para la base de datos: Salinas\n",
      "Procesando ROS\n",
      "../../Datasets/txt/sampled_train/Salinas_ROS.txt\n",
      "Archivo no encontrado\n",
      "Datos procesados y guardados para ROS\n",
      "Procesando SMOTE\n",
      "../../Datasets/txt/sampled_train/Salinas_SMOTE.txt\n",
      "Archivo no encontrado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniel\\anaconda3\\envs\\violence\\lib\\site-packages\\imblearn\\over_sampling\\_smote\\base.py:363: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos procesados y guardados para SMOTE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importación de librerías necesarias\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, ADASYN, BorderlineSMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, OneSidedSelection\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Definir directorios y configuraciones iniciales\n",
    "bases = ['Salinas']\n",
    "\n",
    "# Proceso iterativo sobre cada base de datos\n",
    "for Base in bases:\n",
    "    directorio = f\"../../Datasets/\"\n",
    "    print(\"Inicio del proceso para la base de datos:\", Base)\n",
    "\n",
    "    # Métodos de balanceo de clases\n",
    "    balance_methods = [ \"ROS\", \"SMOTE\"]\n",
    "    sampling_strategies = {\n",
    "        \"ROS\": RandomOverSampler(),\n",
    "        \"SMOTE\": SMOTE(n_jobs=7),\n",
    "    }\n",
    "\n",
    "    # Procesamiento para cada método de balanceo\n",
    "    for method in balance_methods:\n",
    "        print(f\"Procesando {method}\")\n",
    "        try:\n",
    "            # Intenta cargar el archivo procesado previamente\n",
    "            data_path = f\"{directorio}txt/sampled_train/{Base}_{method}.txt\"\n",
    "            print(data_path)\n",
    "            data = np.loadtxt(data_path)\n",
    "            print(f\"{method} ya procesado.\")\n",
    "        except FileNotFoundError:\n",
    "            print(\"Archivo no encontrado\")\n",
    "            # Si no existe, procesa y crea el archivo\n",
    "            original_data_path = f\"{directorio}/txt/train/{Base}.txt\"\n",
    "            data = np.loadtxt(original_data_path)\n",
    "            features = data[:, :-1]\n",
    "            labels = data[:, -1]\n",
    "\n",
    "            # Aplicar método de balanceo\n",
    "            if isinstance(sampling_strategies[method], tuple):\n",
    "                # Para métodos compuestos como SMOTE-TL\n",
    "                for strategy in sampling_strategies[method]:\n",
    "                    features, labels = strategy.fit_resample(features, labels)\n",
    "            else:\n",
    "                features, labels = sampling_strategies[method].fit_resample(features, labels)\n",
    "            ##############            \n",
    "            fmt = ['%0.15f']* features.shape[1] + ['%d']  # Formato flotante para características, entero para etiquetas\n",
    "            np.savetxt(data_path, np.column_stack((features, labels)), fmt=fmt)\n",
    "            print(f\"Datos procesados y guardados para {method}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
